# ğŸ¥ Doctis AI - Assistant de PrÃ©-diagnostic MÃ©dical

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green.svg)](https://fastapi.tiangolo.com)
[![Next.js](https://img.shields.io/badge/Next.js-14-black.svg)](https://nextjs.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **Projet de validation - Module IA GÃ©nÃ©rative & Data Engineering**
>
> EFREI Paris - Promotion 2025

---

## ğŸ‘¥ Auteurs

| Nom | RÃ´le |
|-----|------|
| **Adam Beloucif** | DÃ©veloppeur Full-Stack & ML Engineer |
| **Amina Medjdoub** | DÃ©veloppeur Full-Stack & Data Engineer |

---

## ğŸ“‹ Description

**Doctis AI** est un assistant intelligent de prÃ©-diagnostic mÃ©dical. L'utilisateur dÃ©crit ses symptÃ´mes en langage naturel, et l'IA :

1. **Analyse sÃ©mantiquement** la description des symptÃ´mes
2. **Identifie** la pathologie la plus probable dans sa base de connaissances
3. **GÃ©nÃ¨re** une rÃ©ponse empathique et informative avec des recommandations

### Exemple d'utilisation

```
ğŸ‘¤ Patient: "J'ai mal au ventre en bas Ã  droite depuis ce matin, avec des nausÃ©es et un peu de fiÃ¨vre"

ğŸ¤– Doctis AI: "D'aprÃ¨s l'analyse de vos symptÃ´mes, je dÃ©tecte une possible Appendicite
avec un niveau de confiance de 78%. Cette condition peut Ãªtre sÃ©rieuse et nÃ©cessite
une attention mÃ©dicale urgente. Consultez immÃ©diatement les urgences..."
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND                             â”‚
â”‚                    (Vercel - Next.js)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Interface utilisateur React + Tailwind CSS         â”‚   â”‚
â”‚  â”‚  - Formulaire de saisie des symptÃ´mes              â”‚   â”‚
â”‚  â”‚  - Affichage du diagnostic avec jauge de confiance â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ HTTPS
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BACKEND                              â”‚
â”‚                    (Render - FastAPI)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. SBERT (all-MiniLM-L6-v2)                        â”‚   â”‚
â”‚  â”‚     â†’ Matching sÃ©mantique des symptÃ´mes             â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  2. LLM QuantizÃ© (GGUF - CPU)                       â”‚   â”‚
â”‚  â”‚     â†’ GÃ©nÃ©ration de rÃ©ponses empathiques            â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  3. Base de pathologies (JSON)                      â”‚   â”‚
â”‚  â”‚     â†’ RÃ©fÃ©rentiel de maladies et symptÃ´mes          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stack Technique

| Composant | Technologie | HÃ©bergement |
|-----------|-------------|-------------|
| Frontend | Next.js 14, React, Tailwind CSS | Vercel |
| Backend | FastAPI, Python 3.11 | Render |
| Embeddings | Sentence-Transformers (SBERT) | - |
| LLM | llama-cpp-python (GGUF, CPU) | - |
| RAG | SimilaritÃ© cosinus sur embeddings | - |

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.11+
- Node.js 18+
- Git

### 1. Cloner le repository

```bash
git clone https://github.com/Adam-Blf/Projet-IA-Generative-Doctis-AI-mo.git
cd Projet-IA-Generative-Doctis-AI-mo
```

### 2. Backend (FastAPI)

```bash
# Aller dans le dossier backend
cd backend

# CrÃ©er un environnement virtuel
python -m venv venv

# Activer l'environnement
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# TÃ©lÃ©charger le modÃ¨le GGUF (voir section ci-dessous)

# Lancer le serveur
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 3. Frontend (Next.js)

```bash
# Aller dans le dossier frontend
cd frontend

# Installer les dÃ©pendances
npm install

# Configurer l'URL de l'API
cp .env.example .env.local
# Ã‰diter .env.local pour dÃ©finir NEXT_PUBLIC_API_URL

# Lancer le serveur de dÃ©veloppement
npm run dev
```

---

## ğŸ“¥ TÃ©lÃ©chargement du modÃ¨le LLM

Le modÃ¨le GGUF doit Ãªtre placÃ© dans `backend/models/`.

### Option 1 : Utiliser un modÃ¨le prÃ©-entraÃ®nÃ© (RecommandÃ© pour tester)

```bash
# CrÃ©er le dossier models
mkdir -p backend/models

# TÃ©lÃ©charger TinyLlama (lÃ©ger, ~700 Mo)
wget -O backend/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf \
  https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
```

### Option 2 : Fine-tuner votre propre modÃ¨le

Suivez le guide dans [`training/TRAINING.md`](training/TRAINING.md) pour :
1. Fine-tuner Phi-3 ou TinyLlama sur des donnÃ©es mÃ©dicales
2. Convertir le modÃ¨le en format GGUF
3. Quantifier pour optimiser la taille

---

## ğŸ“ Structure du Projet

```
DoctisAimo/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ pathologies.json    # Base de donnÃ©es des maladies
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ *.gguf              # ModÃ¨le LLM quantifiÃ©
â”‚   â”œâ”€â”€ main.py                 # API FastAPI
â”‚   â””â”€â”€ requirements.txt        # DÃ©pendances Python
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ app/
â”‚   â”‚       â”œâ”€â”€ page.tsx        # Page principale
â”‚   â”‚       â”œâ”€â”€ layout.tsx      # Layout Next.js
â”‚   â”‚       â””â”€â”€ globals.css     # Styles Tailwind
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tailwind.config.ts
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ TRAINING.md             # Guide de fine-tuning
â”‚   â””â”€â”€ train_colab.ipynb       # Notebook Google Colab
â”‚
â””â”€â”€ README.md                   # Ce fichier
```

---

## ğŸ”Œ API Endpoints

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| `GET` | `/` | Page d'accueil de l'API |
| `GET` | `/health` | VÃ©rification de l'Ã©tat du service |
| `GET` | `/pathologies` | Liste des pathologies disponibles |
| `POST` | `/diagnose` | Analyse des symptÃ´mes |

### Exemple de requÃªte `/diagnose`

```bash
curl -X POST "http://localhost:8000/diagnose" \
  -H "Content-Type: application/json" \
  -d '{"symptoms": "J ai mal au ventre en bas Ã  droite avec des nausÃ©es"}'
```

### Exemple de rÃ©ponse

```json
{
  "success": true,
  "matched": true,
  "pathology": {
    "id": "appendicitis",
    "name": "Appendicite",
    "confidence_score": 0.782,
    "severity_level": 5,
    "urgency": "URGENCE MÃ‰DICALE",
    "advice": "Consultez immÃ©diatement les urgences...",
    "specialist": "Chirurgien digestif / Urgentiste"
  },
  "ai_response": "D'aprÃ¨s l'analyse de vos symptÃ´mes...",
  "disclaimer": "Ces informations sont fournies Ã  titre indicatif...",
  "authors": ["Adam Beloucif", "Amina Medjdoub"]
}
```

---

## ğŸ§ª Tests

```bash
# Backend
cd backend
pytest tests/ -v

# Frontend
cd frontend
npm run test
```

---

## ğŸš€ DÃ©ploiement

### Backend sur Render

1. CrÃ©er un nouveau Web Service sur [Render](https://render.com)
2. Connecter le repository GitHub
3. Configurer :
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `uvicorn main:app --host 0.0.0.0 --port $PORT`
4. Ajouter le modÃ¨le GGUF (via stockage externe ou Git LFS)

### Frontend sur Vercel

1. Importer le projet sur [Vercel](https://vercel.com)
2. Configurer le dossier racine : `frontend`
3. Ajouter la variable d'environnement :
   - `NEXT_PUBLIC_API_URL`: URL de votre API Render

---

## âš ï¸ Avertissement

> **Ce service est fourni Ã  titre informatif uniquement et ne remplace en aucun cas une consultation mÃ©dicale professionnelle.**
>
> En cas de symptÃ´mes graves ou persistants, consultez immÃ©diatement un mÃ©decin ou appelez les services d'urgence.

---

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ™ Remerciements

- EFREI Paris pour le module IA GÃ©nÃ©rative & Data Engineering
- Hugging Face pour les modÃ¨les et datasets
- La communautÃ© llama.cpp pour l'optimisation CPU

---

<div align="center">

**Projet rÃ©alisÃ© par Adam Beloucif & Amina Medjdoub**

EFREI Paris - 2025

</div>
